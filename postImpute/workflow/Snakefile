# Load modules
import glob
import os
import subprocess
import pdb
import shutil

# Get the date
from datetime import datetime
i = datetime.now()
TIME = i.strftime('%Y-%m-%d')

# Specify config file
configfile: "workflow/config2.yml"

# Parse config.yml file
OUT = config['outname']
QUERY = config['query']
BCFTOOLS = config['bcftools']['executable']
PYTHON = config['python']

# Format commands and bind paths if using singularity.
if config['singularity']['use_singularity'] == 'true' and config['singularity']['image'] != "none":
    bind_paths = ",".join(set([os.path.dirname(str(x)) for x in list(QUERY.values())] + [os.path.dirname(config['CrossMap']['chain']), os.path.dirname(config['CrossMap']['fasta']), 'OandE', 'accessory', config['singularity']['code']] + list(QUERY.keys())))
    CMD_PREFIX = f"set +u; {config['singularity']['module']}; singularity exec --bind {bind_paths},{os.getcwd()} {config['singularity']['image']}"
    #He has to specify version of singularity...
    CODE = config['singularity']['code']
else:
    CMD_PREFIX = config['cmd_prefix']
    CODE = config['dir']['code']


# Make subdirectories
if not os.path.exists("accessory"): os.mkdir("accessory")
if not os.path.exists("OandE"): os.mkdir("OandE")
for datset in QUERY.keys():
    if not os.path.exists(datset):
        os.mkdir(datset)
        os.mkdir(f"{datset}/tmp")

CHROMS = config['chroms']
if CHROMS == 'all':
    CHROMS = [str(x) for x in range(1, 23)]
    if config['include_x'] == 'yes': CHROMS.append('X')

# Run locally or submit to cluster depending on config.yml
if config['local_run'] == 'true':
    localrules: all, update_alleles_IDs, FixRef, QCcombine_query
else:
    localrules: all, make_rulegraph, set_pheno

# Conditionally set expected outputs of various steps depending on flags in config.yml
def get_all_inputs(wildcards):
    input_list = expand(f"{{rawdata}}/{{rawdata}}_raw{{chrom}}.bed", rawdata=QUERY.keys(), chrom=CHROMS)
    input_list += expand(f"{{rawdata}}/{{rawdata}}_chr{{chrom}}-QC.bed", rawdata=QUERY.keys(), chrom=CHROMS)
    input_list += expand(f"{{rawdata}}/{{rawdata}}_chr{{chrom}}-QC-Ref.bed", rawdata=QUERY.keys(), chrom=CHROMS)
    if config['merge'] == 'true':
        input_list.append(f"{OUT}.bed")
        input_list.append(f"{OUT}-QC.bed")
    input_list += expand(f"{{rawdata}}/.{{rawdata}}-PhenoFixed", rawdata=QUERY.keys())
    return(input_list)

def get_merge_chroms_input(wildcards):
    input_list = expand(f"{{rawdata}}/{{rawdata}}_chr{{chrom}}-QC.bed", chrom=CHROMS)
    return(input_list)

rule all:
    #input: get_all_inputs
    input: expand(f"{OUT}-QC_chr{{chrom}}.bed", chrom=CHROMS), f"{OUT}-report.pdf", f"{OUT}-rulegraph.png"

rule clean:
    input: expand("{query}",query=QUERY.keys())
    shell: "rm -r {input}/*"

rule make_rulegraph:
    output: f"{OUT}-rulegraph.png"
    # shell: "snakemake --rulegraph --configfile workflow/config.yml | {CMD_PREFIX} dot -Tpng > {output}"
    shell: f"touch {{output}}"

rule cross_map:  # Across all datasets, two imputed variants on chromosome 9 are missing an alt/ref field.  Must filter in this step to avoid error in next.
    output: f"{{rawdata}}/{{rawdata}}_hg19_chr{{chrom}}.vcf.gz"
    params:
        in_pre = lambda wildcards: QUERY[wildcards.rawdata],
        out_pre = f"{{rawdata}}/{{rawdata}}_hg19_chr{{chrom}}.vcf",
        awk_string = """awk \'{{if($5!=\".\") print $0}}\'"""
    threads: int(config['CrossMap']['threads'])
    shell: f"{CMD_PREFIX} python3 {config['CrossMap']['exec']} vcf {config['CrossMap']['chain']} {{params.in_pre}}/chr{{wildcards.chrom}}.dose.vcf.gz {config['CrossMap']['fasta']} {{params.out_pre}}; {CMD_PREFIX} {{params.awk_string}} {{params.out_pre}} | bgzip --threads {{threads}} > {{params.out_pre}}.gz; rm {{params.out_pre}}; {CMD_PREFIX} gzip {{params.out_pre}}.unmap"

rule convert_vcfs:
    input: f"{{rawdata}}/{{rawdata}}_hg19_chr{{chrom}}.vcf.gz"
    output: f"{{rawdata}}/{{rawdata}}_raw{{chrom}}.bed"
    shell: f"{CMD_PREFIX} plink --vcf {{input}} --const-fid 0 --keep-allele-order --vcf-min-gp {config['min_gp']} --make-bed --out {{wildcards.rawdata}}/{{wildcards.rawdata}}_raw{{wildcards.chrom}}"

rule QCcombine_query:
    input: "{rawdata}/{rawdata}_raw{chrom}.bed"
    output: "{rawdata}/{rawdata}-QC_chr{chrom}.bed"
    params:
        pre1 = "{rawdata}/{rawdata}_raw{chrom}",
        tvm1 = config['QC']['vm1'], tgm = config['QC']['gm'], tvm2 = config['QC']['vm2'],
        hwe = config['QC']['hwe'], maf = config['QC']['maf'], mbs = config['QC']['mbs'],
    run:
        if config['perform_QC'] == 'true':
            with open("scripts/QCcombine_query.sh", 'w') as QCsh:
                cmd = f"{CMD_PREFIX} {PYTHON} {CODE}/QC.py -i {{params.pre1}} -d {{wildcards.rawdata}} -o {{wildcards.rawdata}}-QC_chr{{wildcards.chrom}} -p plink -tvm1 {{params.tvm1}} -tgm {{params.tgm}} -tvm2 {{params.tvm2}} -hwe {{params.hwe}} -mbs {{params.mbs}} -maf -9 --snps_only; mv {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC_chr{{wildcards.chrom}}.geno* {{wildcards.rawdata}}/tmp; mv {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC_chr{{wildcards.chrom}}.var* {{wildcards.rawdata}}/tmp"
                if config['delete_intermediates'] == 'true': cmd += f"rm -r {{wildcards.rawdata}}/tmp/"
            shell(cmd)
        else:
            shell(f"{CMD_PREFIX} plink --bfile {{params.pre1}} --make-bed --out {{params.pre1}}-QC")

rule restore_strand:
    input: "{rawdata}/{rawdata}-QC_chr{chrom}.bed"
    output: "{rawdata}/{rawdata}-QC-Ref_chr{chrom}.bed"
    params:
        bim_file = "{rawdata}/{rawdata}_raw{chrom}.bim"
    shell: f"{CMD_PREFIX} plink --bfile {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC_chr{{wildcards.chrom}} --make-bed --a2-allele {{params.bim_file}} 6 2 --out {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC-Ref_chr{{wildcards.chrom}}"

# Not tested
rule update_varIDs:
    input: "{rawdata}/{rawdata}-QC-Ref_chr{chrom}.bed"
    output: "{rawdata}/{rawdata}-QC-Ref-varIDs_chr{chrom}.bed"
    shell: """{CMD_PREFIX} awk '{{printf("%s\\t%s:%s\\n",$2,$1,$4)}}' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}.bim > {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}_varIDs.txt; {CMD_PREFIX} plink --bfile {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom} --update-name {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}_varIDs.txt --make-bed --out {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}"""

#TODO: If no case/control datasets, use a user-provided fam file?
#TODO: set_pheno is not working correctly
rule set_pheno:
    input: "{rawdata}/{rawdata}-QC-Ref-varIDs_chr{chrom}.bed"
    output: "{rawdata}/.{rawdata}-PhenoFixed_chr{chrom}"
    run:
        if f"{{wildcards.rawdata}}" in config['case_datasets'].strip().split(","):
            shell("{CMD_PREFIX} sed -i 's/-9$/2/' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}.fam; touch {output}")
        elif f"{{wildcards.rawdata}}" in config['control_datasets'].strip().split(","):
            shell("{CMD_PREFIX} sed -i 's/-9$/1/' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}.fam; touch {output}")
        else:
            shell("touch {output}")

rule merge_inputs:
    input: expand("{rawdata}/{rawdata}-QC-Ref-varIDs_chr{{chrom}}.bed", rawdata=QUERY.keys()), expand("{rawdata}/.{rawdata}-PhenoFixed_chr{{chrom}}", rawdata=QUERY.keys())
    output: f"{OUT}_chr{{chrom}}.bed"
    params:
        input_list = ",".join([f"{x}/{x}-QC-Ref-varIDs_chr{{chrom}}" for x in QUERY.keys()])
    run:
        if config['merge'] == 'true':
            shell(f"{CMD_PREFIX} {PYTHON} {CODE}/mergeInputs.py -i {{params.input_list}} -d {os.getcwd()} -o {OUT}_chr{{wildcards.chrom}} -p plink --drop_pos_dups")

rule filter_merged:
    input: f"{OUT}_chr{{chrom}}.bed"
    output: f"{OUT}-QC_chr{{chrom}}.bed"
    shell: f"{CMD_PREFIX} plink --bfile {OUT}_chr{{wildcards.chrom}} --maf {config['QC']['maf']} --keep-allele-order --make-bed --out {OUT}-QC_chr{{wildcards.chrom}}"

rule make_report:
    input: expand(f"{OUT}-QC_chr{{chrom}}.bed", chrom=CHROMS), f"{OUT}-rulegraph.png"
    output: f"{OUT}-report.pdf"
    run:
        with open("scripts/gather_report_data.sh", 'w') as report_cmds:
            report_cmds.write("wc -l */*txt | grep -v -e scripts -e total | awk \'{split($2,a,\"_\"); split(a[2],b,\".\"); split(b[1],c,\"-\"); print a[1],b[3],c[1],$1}\' > accessory/chromfilter.stats\n")
            report_cmds.write("; wc -l */*dupvar | awk \'{split($2,a,\"_\"); split(a[2],b,\".\"); split(b[1],c,\"-\"); print a[1],b[2],c[1],$1}\' | grep -v total | cut -d \"/\" -f 2 >> accessory/chromfilter.stats\n")
            report_cmds.write("; grep variants */*raw*log | grep QC | awk \'{split($1,b,\"/\"); split(b[2],c,\"_\"); print c[1],c[2]}\' | tr \":\" \" \" | sed \'s/raw/chr/\' | sed \'s/.log/ raw/\' >> accessory/chromfilter.stats\n")
            report_cmds.write(f"wc -l */*-QC-Ref.bim | grep -v -e '_chr' -e total >> accessory/dataset_filter.stats; wc -l mergeSNPs.txt >> accessory/dataset_filter.stats; grep retained {OUT}-QC.log >> accessory/dataset_filter.stats\n")
        cmd = f"{CMD_PREFIX} sh scripts/gather_report_data.sh; {CMD_PREFIX} Rscript scripts/DataPrep_report.Rmd -f accessory/filter.stats -F accessory/FixRef.stats -r accessory/ref_freqs.txt -d accessory/dat_freqs.txt -y workflow/config.yaml -rg {OUT}-rulegraph.png -o {{output}}"
        # shell(cmd)
        shell(f"touch {OUT}-report.pdf")
#TODO: ensure that ref/alt has been maintained in the final dataset




