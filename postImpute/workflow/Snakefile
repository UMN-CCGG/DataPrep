# Load modules
import glob
import os
import subprocess
import pdb
import shutil

# Get the date
from datetime import datetime
i = datetime.now()
TIME = i.strftime('%Y-%m-%d')

# Specify config file
configfile: "workflow/config.yml"

# Parse config.yml file
OUT = config['outname']
QUERY = config['query']
BCFTOOLS = config['bcftools']['executable']
PYTHON = config['python']


#TODO: Add check that the scripts directory is findable
# Format commands and bind paths if using singularity.
if config['singularity']['use_singularity'] == 'true' and config['singularity']['image'] != "none":
    bind_paths = ",".join(set([os.path.dirname(str(x)) for x in list(QUERY.values())] + [os.path.dirname(config['CrossMap']['chain']), os.path.dirname(config['CrossMap']['fasta']), 'OandE', 'accessory', config['singularity']['code']] + list(QUERY.keys())))
    CMD_PREFIX = f"set +u; {config['singularity']['module']}; singularity exec --bind {bind_paths},{os.getcwd()} {config['singularity']['image']}"
    #He has to specify version of singularity...
    CODE = config['singularity']['code']
else:
    CMD_PREFIX = config['cmd_prefix']
    CODE = config['dir']['code']


# Make subdirectories
if not os.path.exists("accessory"): os.mkdir("accessory")
if not os.path.exists("OandE"): os.mkdir("OandE")
for datset in QUERY.keys():
    if not os.path.exists(datset):
        os.mkdir(datset)
        os.mkdir(f"{datset}/tmp")

CHROMS = config['chroms']
if CHROMS == 'all':
    CHROMS = [str(x) for x in range(1, 23)]
    if config['include_x'] == 'yes': CHROMS.append('X')

# Run locally or submit to cluster depending on config.yml
if config['local_run'] == 'true':
    localrules: all, update_alleles_IDs, FixRef, QCcombine_query
else:
    localrules: all, make_rulegraph, set_pheno

# Conditionally set expected outputs of various steps depending on flags in config.yml
def get_all_inputs(wildcards):
    input_list = expand(f"{{rawdata}}/{{rawdata}}_raw{{chrom}}.bed", rawdata=QUERY.keys(), chrom=CHROMS)
    input_list += expand(f"{{rawdata}}/{{rawdata}}_chr{{chrom}}-QC.bed", rawdata=QUERY.keys(), chrom=CHROMS)
    input_list += expand(f"{{rawdata}}/{{rawdata}}_chr{{chrom}}-QC-Ref.bed", rawdata=QUERY.keys(), chrom=CHROMS)
    if config['merge'] == 'true':
        input_list.append(f"{OUT}.bed")
        input_list.append(f"{OUT}-QC.bed")
    input_list += expand(f"{{rawdata}}/.{{rawdata}}-PhenoFixed", rawdata=QUERY.keys())
    return(input_list)

def get_merge_chroms_input(wildcards):
    input_list = expand(f"{{rawdata}}/{{rawdata}}_chr{{chrom}}-QC.bed", chrom=CHROMS)
    return(input_list)

rule all:
    #input: get_all_inputs
    input: expand(f"{OUT}-QC_chr{{chrom}}.bed", chrom=CHROMS), f"{OUT}-report.pdf", f"{OUT}-rulegraph.png"

rule clean:
    input: expand("{query}",query=QUERY.keys())
    shell: "rm -r {input}/*"

rule make_rulegraph:
    output: f"{OUT}-rulegraph.png"
    params: mod_cmd = CMD_PREFIX.replace(f"set +u; {config['singularity']['module']};", "")
    shell: f"{config['singularity']['module']}; snakemake --rulegraph --configfile workflow/config.yml | {{params.mod_cmd}} dot -Tpng > {{output}}"
    # shell: "touch {OUT}-rulegraph.png"

#TODO: add option to download chain and fasta files; but recall that raw chain file must be filtered to exclude any non-canonical chromosome names
rule cross_map:  #TODO Across all datasets, two imputed variants on chromosome 9 are missing an alt/ref field.  Must filter in this step to avoid error in next.  Still not working
    output: f"{{rawdata}}/{{rawdata}}_hg19_chr{{chrom}}.vcf.gz"
    params:
        in_pre = lambda wildcards: QUERY[wildcards.rawdata],
        out_pre = f"{{rawdata}}/{{rawdata}}_hg19_chr{{chrom}}.vcf",
        awk_string = """awk \'{if($5!=\".\") print $0}\'"""
    threads: int(config['CrossMap']['threads'])
    run:
        cmd=""
        if config["CrossMap"]['download_refs'] == "true":
            cmd += f"wget -P accessory/ {config['CrossMap']['fasta']}; wget -P accessory/ {config['CrossMap']['chain']} "
            if config['CrossMap']['fasta'].endswith(".gz"): cmd += f"; gunzip accessory/{os.path.basename(config['CrossMap']['fasta'])}"
            chrom_string = " ".join([f"{x} chr{x}" for x in range(1,23)])
            if config['CrossMap']['fasta'].endswith(".gz"): cmd += f"; zcat {config['CrossMap']['fasta']} | "
            else: cmd += f"; cat {config['CrossMap']['fasta']} | "
            cmd += f"awk \'BEGIN{{split(" + chrom_string + f",chroms); if($3 in chroms | $8 in chroms) print $0}}\' | gzip > accessory/{os.path.basename(config['CrossMap']['chain'])}.flt.gz; "
            config['CrossMap']['fasta'] = f"accessory/{os.path.basename(config['CrossMap']['fasta']).strip('.gz')}"
            config['CrossMap']['chain'] = f"accessory/{os.path.basename(config['CrossMap']['chain'])}.flt.gz"
        cmd += f"{CMD_PREFIX} python3 {config['CrossMap']['exec']} vcf {config['CrossMap']['chain']} {{params.in_pre}}/chr{{wildcards.chrom}}.dose.vcf.gz {config['CrossMap']['fasta']} {{params.out_pre}}; {CMD_PREFIX} {{params.awk_string}} {{params.out_pre}} | bgzip --threads {{threads}} > {{params.out_pre}}.gz; rm {{params.out_pre}}; {CMD_PREFIX} gzip {{params.out_pre}}.unmap"
        print(cmd)
        shell(cmd)

rule convert_vcfs:
    input: f"{{rawdata}}/{{rawdata}}_hg19_chr{{chrom}}.vcf.gz"
    output: f"{{rawdata}}/{{rawdata}}_raw{{chrom}}.bed"
    shell: f"{CMD_PREFIX} plink --vcf {{input}} --const-fid 0 --keep-allele-order --vcf-min-gp {config['min_gp']} --make-bed --out {{wildcards.rawdata}}/{{wildcards.rawdata}}_raw{{wildcards.chrom}}"

rule QCcombine_query:
    input: "{rawdata}/{rawdata}_raw{chrom}.bed"
    output: "{rawdata}/{rawdata}-QC_chr{chrom}.bed"
    params:
        pre1 = "{rawdata}/{rawdata}_raw{chrom}",
        tvm1 = config['QC']['vm1'], tgm = config['QC']['gm'], tvm2 = config['QC']['vm2'],
        hwe = config['QC']['hwe'], maf = config['QC']['maf'], mbs = config['QC']['mbs'],
    run:
        if config['perform_QC'] == 'true':
            with open("scripts/QCcombine_query.sh", 'w') as QCsh:
                cmd = f"{CMD_PREFIX} {PYTHON} {CODE}/QC.py -i {{params.pre1}} -d {{wildcards.rawdata}} -o {{wildcards.rawdata}}-QC_chr{{wildcards.chrom}} -p plink -tvm1 {{params.tvm1}} -tgm {{params.tgm}} -tvm2 {{params.tvm2}} -hwe {{params.hwe}} -mbs {{params.mbs}} -maf -9 --snps_only; mv {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC_chr{{wildcards.chrom}}.geno* {{wildcards.rawdata}}/tmp; mv {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC_chr{{wildcards.chrom}}.var* {{wildcards.rawdata}}/tmp"
                if config['delete_intermediates'] == 'true': cmd += f"rm -r {{wildcards.rawdata}}/tmp/"
            shell(cmd)
        else:
            shell(f"{CMD_PREFIX} plink --bfile {{params.pre1}} --make-bed --out {{params.pre1}}-QC")

rule restore_strand:
    input: "{rawdata}/{rawdata}-QC_chr{chrom}.bed"
    output: "{rawdata}/{rawdata}-QC-Ref_chr{chrom}.bed"
    params:
        bim_file = "{rawdata}/{rawdata}_raw{chrom}.bim"
    shell: f"{CMD_PREFIX} plink --bfile {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC_chr{{wildcards.chrom}} --make-bed --a2-allele {{params.bim_file}} 6 2 --out {{wildcards.rawdata}}/{{wildcards.rawdata}}-QC-Ref_chr{{wildcards.chrom}}"

# Not tested since adding sex
rule update_varIDs_and_sex:
    input: "{rawdata}/{rawdata}-QC-Ref_chr{chrom}.bed"
    output: "{rawdata}/{rawdata}-QC-Ref-varIDs_chr{chrom}.bed"
    params: sex_dat = config['phenotype_data']['sex_file']
    shell: """
    sed \'s/^/0\t/\' {params.sex_dat} > accessory/sex.txt;
    {CMD_PREFIX} awk '{{printf("%s\\t%s:%s\\n",$2,$1,$4)}}' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}.bim > {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}_varIDs.txt; 
    {CMD_PREFIX} plink --bfile {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom} --update-name {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref_chr{wildcards.chrom}_varIDs.txt --update-sex accessory/sex.txt --make-bed --out {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}
    """

#TODO: If no case/control datasets, use a user-provided fam file?
#TODO: set_pheno is not working correctly
rule set_pheno:
    input: "{rawdata}/{rawdata}-QC-Ref-varIDs_chr{chrom}.bed"
    output: "{rawdata}/.{rawdata}-PhenoFixed_chr{chrom}"
    params: pheno_dat = config['phenotype_data']['pheno_file']
    run:
        if os.path.exists(params.pheno_dat):
            shell("sed \'s/^/0\t/\' {params.pheno_dat} > accessory/pheno_file.txt; "
                  "{CMD_PREFIX} plink --bfile {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom} --pheno accessory/pheno_file.txt --keep-allele-order --make-bed --out {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs-pheno_chr{wildcards.chrom};"
                  "mv {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs-pheno_chr{wildcards.chrom}.bed {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}.bed"
                  "mv {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs-pheno_chr{wildcards.chrom}.bim {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}.bim"
                  "mv {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs-pheno_chr{wildcards.chrom}.fam {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}.fam"
                  "touch {output}")
        elif f"{wildcards.rawdata}" in config['phenotype_data']['case_datasets'].strip().split(","):
            shell("{CMD_PREFIX} sed -i 's/-9$/2/' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}.fam; touch {output}")
        elif f"{wildcards.rawdata}" in config['phenotype_data']['control_datasets'].strip().split(","):
            shell("{CMD_PREFIX} sed -i 's/-9$/1/' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref-varIDs_chr{wildcards.chrom}.fam; touch {output}")
        else:
            shell("touch {output}")


rule merge_inputs:
    input: expand("{rawdata}/{rawdata}-QC-Ref-varIDs_chr{{chrom}}.bed", rawdata=QUERY.keys()), expand("{rawdata}/.{rawdata}-PhenoFixed_chr{{chrom}}", rawdata=QUERY.keys())
    output: f"{OUT}_chr{{chrom}}.bed"
    params:
        input_list = ",".join([f"{x}/{x}-QC-Ref-varIDs_chr{{chrom}}" for x in QUERY.keys()])
    run:
        if config['merge'] == 'true':
            shell(f"{CMD_PREFIX} {PYTHON} {CODE}/mergeInputs.py -i {{params.input_list}} -d {os.getcwd()} -o {OUT}_chr{{wildcards.chrom}} -p plink --drop_pos_dups")
        else:
            shell("{CMD_PREFIX} plink --bfile {input_list} --make-bed --keep-allele-order --out {output}")

rule filter_merged:
    input: f"{OUT}_chr{{chrom}}.bed"
    output: f"{OUT}-QC_chr{{chrom}}.bed"
    shell: f"{CMD_PREFIX} plink --bfile {OUT}_chr{{wildcards.chrom}} --maf {config['QC']['maf']} --keep-allele-order --make-bed --out {OUT}-QC_chr{{wildcards.chrom}}"

#TODO extract chunks and samples excluded from input directory
#TODO extract number of variants that were unmapped during CrossMap
rule make_report:
    input: expand(f"{OUT}-QC_chr{{chrom}}.bed", chrom=CHROMS), f"{OUT}-rulegraph.png"
    output: f"{OUT}-report.pdf"
    run:
        with open("accessory/chunks_excluded.txt", 'w') as exc_file:
            exc_file.write(f"dataset\tchunk\tnum.snps\tref.ovlp\tnum.low.sample.callrate\n")
            for dataset,directory in QUERY.items():
                with open(f"{directory}/chunks-excluded.txt") as dat_chunks:
                    for line in dat_chunks:
                        if not line.startswith("#"): exc_file.write(f"{dataset}\t" + line)
                        if not line.endswith("\n"): exc_file.write(f"\n")
        with open("accessory/snps_excluded.txt", 'w') as exc_file:
            exc_file.write(f"dataset\tsite\tfilter\tinfo\n")
            for dataset,directory in QUERY.items():
                with open(f"{directory}/snps-excluded.txt") as dat_chunks:
                    for line in dat_chunks:
                        if not line.startswith("#"): exc_file.write(f"{dataset}\t" + line.replace(" ", "-"))
                        if not line.endswith("\n"): exc_file.write(f"\n")
        with open("scripts/gather_report_data.sh", 'w') as report_cmds:
            report_cmds.write("wc -l */*fltdSNPs*txt | grep -v -e scripts -e total | awk \'{split($2,a,\"/\"); split(a[2],b,\"QC_\"); split(b[2],c,\".\"); print a[1],c[1],c[3],$1}\' > accessory/chromfilter.stats\n")
            report_cmds.write("wc -l */*dupvar | awk \'{split($2,a,\"/\"); split(a[2],b,\"QC_\"); split(b[2],c,\".\"); print a[1],c[1],c[2],$1}\' | grep -v total >> accessory/chromfilter.stats\n")
            report_cmds.write("for f in */*unmap.gz; do printf \"${f}\\t\"; zcat $f | wc -l ; done | awk \'{split($1,a,\"/\"); n=split(a[2],b,\"_\"); split(b[n],c,\".\"); print a[1],c[1],c[3],$2}\' >> accessory/chromfilter.stats\n")
            report_cmds.write("grep variants */*raw*log | grep QC | awk \'{split($1,b,\"/\"); n=split(b[2],c,\"_\"); print b[1],c[n]}\' | tr \":\" \" \" | sed \'s/raw/chr/\' | sed \'s/.log/ raw/\' >> accessory/chromfilter.stats\n")
            report_cmds.write("wc -l */*-QC-Ref_chr*.bim | awk \'{split($2,a,\"/\"); n=split(a[2],b,\"_\"); printf(\"%s\\t%s\\tpostQC\\t%s\\n\",a[1],b[n],$1)}\' | sed \'s/.bim//\' | grep -v total >> accessory/chromfilter.stats\n")
            report_cmds.write("grep people *QC_chr*log | grep -v males | awk \'{n=split($1,a,\"_\"); print a[n]}\' | sed \'s/.log:/\\tMAF\\t/\' > accessory/merge.stats\n")
            if config['merge'] == 'true':
                report_cmds.write("wc -l *mergeSNPs.txt | grep -v total | awk \'{n=split($2,b,\"_\"); printf(\"%s\\tovlp\\t%s\\n\",b[n-1],$1)}\' >> accessory/merge.stats\n")
            else:
                report_cmds.write(f"wc -l {OUT}_chr*.bim | awk \'{{split($2,a,\"/\"); n=split(a[2],b,\"_\"); printf(\"%s\\tovlp\\t%s\\t%s\\n\",a[1],b[n],$1)}}\' | sed \'s/.bim//\' | grep -v total >> accessory/merge.stats\n")
            report_line = f"echo \'rmarkdown::render(\"scripts/postImpute_report.Rmd\", output_file=\"{OUT}-report.pdf\", " \
                          f"params=list(chrom_file=\"accessory/chromfilter.stats\", " \
                          f"merge_file=\"accessory/merge.stats\", chunk_file=\"accessory/chunks_excluded.txt\", " \
                          f"snp_file=\"accessory/snps_excluded.txt\", " \
                          f"rulegraph_file=\"{OUT}-rulegraph.png\", " \
                          f"config_file=\"workflow/config.yml\"))\' | R --vanilla"
            report_cmds.write(report_line)

        shell(f"{CMD_PREFIX} sh scripts/gather_report_data.sh; mv scripts/{OUT}-report.pdf {OUT}-report.pdf")

#TODO: ensure that ref/alt has been maintained in the final dataset




