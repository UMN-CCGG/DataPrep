\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={DataPrep Report},
            pdfauthor={Patrick Monnahan},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{float}
\usepackage{caption}
\usepackage{color}
\usepackage{lscape}
\newcommand{\blandscape}{\begin{landscape}}
\newcommand{\elandscape}{\end{landscape}}
\captionsetup[figure]{name=Figure, labelfont=bf}
\renewcommand{\thefigure}{S\arabic{figure}}

\captionsetup[table]{name=Table, labelfont=bf}
\renewcommand{\thetable}{S\arabic{table}}

\title{DataPrep Report}
\author{Patrick Monnahan}
\date{30 April, 2020}

\begin{document}
\maketitle

\hypertarget{pre-imputation-report}{%
\section{Pre-Imputation Report}\label{pre-imputation-report}}

\hypertarget{preparing-samples}{%
\subsection{Preparing samples}\label{preparing-samples}}

This report contains summary information of the process that was used
filter and prepare different datasets for imputation via the Michigan
Imputation Server (likely using the TOPMed imputation panel). Beginning
with one or more datasets in PLINK format, optional updates are made to
the chromosome and variant IDs in an attempt to make these uniform
across datasets. Additionally, alleles can be converted with a provided
key. Then, a series of steps are performed in an attempt to correctly
set the reference versus alternative alleles as implied by a specified
reference genome. With this `fixed' dataset, we perform a series of
basic QC steps described in a subsequent section. After QC, we restore
the reference alleles determined in the previous step as well as any
phenotypes or sex specification that was lost. Finally, the datasets are
split by chromosome and converted into separate sorted, gzipped VCF
files. The DAG representing this workflow is provided at the end of this
document, although it is likely too large to be conveniently viewed.

The following datasets were used as input:

\begin{longtable}[]{@{}ll@{}}
\toprule
Dataset & Directory\tabularnewline
\midrule
\endhead
cclrp & PATH\_TO\_PLINK\_BED\_PREFIX\tabularnewline
\bottomrule
\end{longtable}

and the pipeline was carried out using the following singularity image:

\begin{verbatim}
## [1] "PATH_TO_SIgrep NGULARITY_IMAGE_AncestryInference.sif"
\end{verbatim}

\hypertarget{reference-allele-fixing}{%
\subsection{Reference allele fixing}\label{reference-allele-fixing}}

In contrast to a VCF, where alleles are specified with respect to a
specified reference genome (reference versus alternative alleles),
PLINK-formatted files often specify alleles as major/minor alleles based
on the frequency in the dataset. In an attempt to recover, the
reference/altnerative specification for a particular reference genome,
we use the bcftools plugin `+fixref', which requires not only the
reference sequence (fasta) file, but also a VCF file containing variant
sites that specify the candidates for allele fixing/swapping. By
default, the pipeline will download the following files for the hg19
reference genome

Reference fasta:
\url{ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/reference/human_g1k_v37.fasta.gz}

Reference VCF (1000Genomes):
\url{ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b150_GRCh37p13/VCF/All_20170710.vcf.gz}

However, it is important to realize that some (in fact, many) sites will
be unable to be resolved by this method, particularly
A\textless{}-\textgreater{}T and C\textless{}-\textgreater{}G
polymorphisms. In these cases, it is not possible to tell if such a
polymorphism has simply swapped the reference versus alternative allele
OR if the polymorphism has been specified relative to the opposite
strand of the reference genome.

Below is a summary of this procedure:

This figure provides the summary of the different possible states as
determined by bcftools +fixref:

\begin{center}\includegraphics{test_files/figure-latex/FixRef-StateSummary-1} \end{center}

The `ref-mismatch' sites are the ones in which the program will try to
take action to correct.

The number of sites in which the corresponding action was taken:

\begin{center}\includegraphics{test_files/figure-latex/FixRef-ActionTaken-1} \end{center}

My understanding is that `swapped' indicates that the REF/ALT allele is
simply swapped in the query dataset, whereas `flipped' indicates that
the strand was flipped. With the exception of the `unresolved' class,
these `corrected' sites will be included in the new totals shown below.
The `unresolved' sites are essentially lost data and are filtered from
the final datasets.

The new total number of sites following the changes made by bcftools
+fixref:

\begin{center}\includegraphics{test_files/figure-latex/FixRef-NewTotals-1} \end{center}

An indication of whether the above procedure worked correctly is to plot
frequency of an allele in the query population against the frequency in
the reference population and look for an obviously positive correlation.
The graphs below provide such plots for each of the query datasets:

\begin{center}\includegraphics{test_files/figure-latex/AF-correlation-1} \end{center}

\begin{verbatim}
## [1] "0.05"
\end{verbatim}

This missingness criterion is applied after first excluding samples that
exceeded the following rate of missingness across variants:

\begin{verbatim}
## [1] "0.1"
\end{verbatim}

The following table summarizes the number of variants excluded due to
each of the filters mentioned above:

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
Dataset & Missingness & HWE & MAF & Duplicates & Total &
Raw\tabularnewline
\midrule
\endhead
aall0232 & 45387 & 0 & 9839 & 0 & 55226 & 916832\tabularnewline
aric & 1446 & 0 & 14736 & 0 & 16182 & 569874\tabularnewline
cog1 & 29868 & 0 & 33431 & 0 & 63299 & 904996\tabularnewline
cog2 & 38515 & 0 & 14348 & 0 & 52863 & 493405\tabularnewline
stjude & 20309 & 0 & 6414 & 0 & 26723 & 532143\tabularnewline
\bottomrule
\end{longtable}

\begin{center}\includegraphics{test_files/figure-latex/chrom-filter-stats-1} \end{center}

\begin{center}\includegraphics{test_files/figure-latex/chrom-filter-stats-2} \end{center}

\newpage

\hypertarget{rule-graph}{%
\subsection{Rule Graph}\label{rule-graph}}

Below is a directed acyclic graph depicting the steps involved in this
post-imputation QC pipeline. When possible, computation within each node
was parallelized by dataset, chromosome, etc. The full DAG visualizing
the parallel computing can be generated via:

\begin{verbatim}
snakemake --dag | dot -Tpng > jobgraph.png
\end{verbatim}

from within the directory that the post-imputation QC was carried out.
These are typically too large to fit easily in a pdf, and so were not
included in this report.

\begin{figure}[H]

{\centering \includegraphics[width=5.38in,height=11cm]{/Users/pmonnaha/Documents/Research/DataPrep/data/ewingsOG-rulegraph} 

}

\caption{A rule graph showing the different steps of the bioinformatic analysis that is included in the Snakemake workflow.}\label{fig:unnamed-chunk-1}
\end{figure}

\newpage

\hypertarget{reproducibility}{%
\subsection{Reproducibility}\label{reproducibility}}

The code for reproducing this analysis is available
\href{https://github.com/pmonnahan/DataPrep}{here}. The repo contains:

\begin{itemize}
\tightlist
\item
  A Snakemake workflow for running all steps.
\item
  A collection of scripts to acheive individual steps
\item
  A Singularity definitions file that can be used to generate the
  Singularity image used to run all steps. ** This image file is also
  directly available upon request
\end{itemize}

The code for reproducing this report is available
\href{https://github.com/pmonnahan/DataPrep/blob/master/scripts/DataPrep_report.Rmd}{here}.

The input files for the figures produced herein are from:

\begin{verbatim}
## $flt_file
## [1] "data/filter.stats"
## 
## $FixRef_file
## [1] "data/FixRef.stats2"
## 
## $rulegraph_file
## [1] "data/ewingsOG-rulegraph.png"
## 
## $ref_freqs
## [1] "data/ref_freqs.txt"
## 
## $dat_freq
## [1] "data/dat_freqs2.txt"
## 
## $config_file
## [1] "workflow/config.yml"
\end{verbatim}

Also, see the config.yml in the workflow directory for full list of
parameter inputs and settings.

The results in this supplementary were generated in the following R
environment:

\footnotesize

\begin{verbatim}
## R version 3.6.1 (2019-07-05)
## Platform: x86_64-apple-darwin18.6.0 (64-bit)
## Running under: macOS Mojave 10.14.6
## 
## Matrix products: default
## BLAS/LAPACK: /usr/local/Cellar/openblas/0.3.7/lib/libopenblasp-r0.3.7.dylib
## 
## locale:
## [1] en_US/en_US.UTF-8/en_US/C/en_US/en_US
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] formattable_0.2.0.1 magrittr_1.5        tidyr_1.0.2        
## [4] dplyr_0.8.5         yaml_2.2.1          optparse_1.6.4     
## [7] reshape2_1.4.3      ggplot2_3.3.0      
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.3        highr_0.8         pillar_1.4.3      compiler_3.6.1   
##  [5] plyr_1.8.6        tools_3.6.1       digest_0.6.25     evaluate_0.14    
##  [9] lifecycle_0.2.0   tibble_2.1.3      gtable_0.3.0      png_0.1-7        
## [13] pkgconfig_2.0.3   rlang_0.4.5       xfun_0.12         withr_2.1.2      
## [17] stringr_1.4.0     knitr_1.28        htmlwidgets_1.5.1 vctrs_0.2.4      
## [21] grid_3.6.1        tidyselect_1.0.0  getopt_1.20.3     glue_1.3.1       
## [25] R6_2.4.1          rmarkdown_2.1     farver_2.0.3      purrr_0.3.3      
## [29] ellipsis_0.3.0    scales_1.1.0      htmltools_0.4.0   assertthat_0.2.1 
## [33] colorspace_1.4-1  labeling_0.3      stringi_1.4.6     munsell_0.5.0    
## [37] crayon_1.3.4
\end{verbatim}

\normalsize

\end{document}
