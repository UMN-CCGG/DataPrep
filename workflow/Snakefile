# Load modules
import glob
import os
import subprocess
import pdb
import shutil

# Get the date
from datetime import datetime
i = datetime.now()
TIME = i.strftime('%Y-%m-%d')

# Specify config file
configfile: "workflow/config.yml"

# Parse config.yml file
OUT = config['outname']
QUERY = config['query']
BCFTOOLS = config['bcftools']['executable']
PYTHON = config['python']

# Is reference info provided in config file or do we download?
REFASTA = config['reference']['refFasta']
REFVCF = config['reference']['refVCF']
if config['updates']['FixRef'] == "true":
    if config['download_reference'] == 'true':
        REFASTA = f"{os.getcwd()}/RefAnnotationData/human_g1k_v37.fasta.gz"
        REFVCF = f"{os.getcwd()}/RefAnnotationData/All_20170710.vcf.gz"
    else:
        assert (REFASTA != "none" and REFVCF != "none"), "Must provide a reference fasta and VCF in workflow/config.yml file"
        assert os.path.exists(config['reference']['refFasta']), f"Did not find reference fasta: {config['reference']['refFasta']}"
        assert os.path.exists(config['reference']['refVCF']), f"Did not find reference VCF: {config['reference']['refVCF']}"

# Format commands and bind paths if using singularity.
if config['singularity']['use_singularity'] == 'true' and config['singularity']['image'] != "none":
    bind_paths = ",".join(set([os.path.dirname(str(x)) for x in list(QUERY.values())] + [os.path.dirname(REFASTA), os.path.dirname(REFVCF), os.path.dirname(config['updates']['chrom_key']), 'OandE', 'accessory', config['singularity']['code']] + list(QUERY.keys())))
    CMD_PREFIX = f"set +u; {config['singularity']['module']}; singularity exec --bind {bind_paths},{os.getcwd()} {config['singularity']['image']}"
    #He has to specify version of singularity...
    CODE = config['singularity']['code']
else:
    CMD_PREFIX = config['cmd_prefix']
    CODE = config['dir']['code']


# Make subdirectories
if not os.path.exists("RefAnnotationData"): os.mkdir("RefAnnotationData")
if not os.path.exists("accessory"): os.mkdir("accessory")
if not os.path.exists("OandE"): os.mkdir("OandE")
for datset in QUERY.keys():
    if not os.path.exists(datset):
        os.mkdir(datset)
        os.mkdir(f"{datset}/tmp")

CHROMS = config['chroms']
if CHROMS == 'all':
    CHROMS = [str(x) for x in range(1, 23)]
    if config['include_x'] == 'yes': CHROMS.append('X')

# Run locally or submit to cluster depending on config.yml
if config['local_run'] == 'true':
    localrules: all, update_alleles_IDs, FixRef, QCcombine_query
else:
    localrules: all, make_rulegraph

# Conditionally set expected outputs of various steps depending on flags in config.yml
def get_all_inputs(wildcards):
    input_list = [f"{OUT}-report.pdf", f"{OUT}-rulegraph.png"]
    if config['merge'] == 'true':
        input_list.append(f"{OUT}.bed")
    if config['impute_prep'] == 'true':
        input_list += expand(f"{{rawdata}}/{{rawdata}}.chr{{chrom}}.vcf.gz", rawdata=QUERY.keys(), chrom=CHROMS)
    if config['download_reference'] == 'true':
        input_list += [REFASTA, REFVCF]
    return(input_list)

rule all:
    input: get_all_inputs
    # input: expand(f"{{rawdata}}/{{rawdata}}.chr{{chrom}}.vcf.gz", rawdata=QUERY.keys(), chrom=CHROMS), f"{OUT}-report.pdf", f"{OUT}-rulegraph.png"

rule clean:
    shell: "rm RefAnnotationData/*; rm -r {wildcards.rawdata}/*"

rule make_rulegraph:
    output: f"{OUT}-rulegraph.png"
    params: mod_cmd = CMD_PREFIX.replace(f"set +u; {config['singularity']['module']};", "")
    shell: "snakemake --rulegraph --configfile workflow/config.yml | {params.mod_cmd} dot -Tpng > {output}"

rule update_alleles_IDs: # Update chromosome labels, SNP IDs, and alleles
    output: "{rawdata}/tmp/{rawdata}_alleles_IDs.bed"
    params:
        in_pre = lambda wildcards: QUERY[wildcards.rawdata],
        prefix = "{rawdata}/tmp/{rawdata}",
        exec = f"{CMD_PREFIX} plink",
        alleles = config['updates']['allele_key'],
        ids = config['updates']['ID_key'],
        chrom_ids = config['updates']['chrom_key']
    run:
        shell(f"cut -f 2 {{params.in_pre}}.bim | sort | uniq -d > {{params.prefix}}.dups")
        if config['updates']['ID_key'] != "none":
            if config['updates']['allele_key'] != "none":
                if config['updates']['chrom_key'] != "none":
                    shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-chr {{params.chrom_ids}} --make-bed --out {{params.prefix}}.chrom ; {{params.exec}} --bfile {{params.prefix}}.chrom --update-alleles {{params.alleles}} --make-bed --out {{params.prefix}}_alleles; {{params.exec}} --bfile {{params.prefix}}_alleles --update-name {{params.ids}} --make-bed --out {{params.prefix}}_alleles_IDs")
                else:
                    shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-alleles {{params.alleles}} --make-bed --out {{params.prefix}}_alleles; {{params.exec}} --bfile {{params.prefix}}_alleles --update-name {{params.ids}} --make-bed --out {{params.prefix}}_alleles_IDs")
            elif config['updates']['chrom_key'] != "none":
                shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-chr {{params.chrom_ids}} --make-bed --out {{params.prefix}}.chrom; {{params.exec}} --bfile {{params.prefix}}.chrom --update-name {{params.ids}} --make-bed --out {{params.prefix}}_alleles_IDs")
            else:
                shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-name {{params.ids}} --make-bed --out {{params.prefix}}_alleles_IDs")
        else:
            if config['updates']['allele_key'] != "none":
                if config['updates']['chrom_key'] != "none":
                    shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-chr {{params.chrom_ids}} --make-bed --out {{params.prefix}}.chrom; {{params.exec}} --bfile {{params.prefix}}.chrom --update-alleles {{params.alleles}} --make-bed --out {{params.prefix}}_alleles")
                else:
                    shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-alleles {{params.alleles}} --make-bed --out {{params.prefix}}_alleles_IDs")
            elif config['updates']['chrom_key'] != "none":
                shell(f"{CMD_PREFIX} sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --update-chr {{params.chrom_ids}} --make-bed --out {{params.prefix}}_alleles_IDs")
            else:
                shell(f"sed -i 's/_/-/g' {{params.in_pre}}.fam; {{params.exec}} --bfile {{params.in_pre}} --exclude {{params.prefix}}.dups --make-bed --out {{params.prefix}}_alleles_IDs")


rule download_Refs:  # Download hg19 and the 1000Genomes VCF for use in strand flipping of query data
    output: REFVCF, REFASTA
    shell: "{CMD_PREFIX} sh {CODE}/DownloadRefs.sh"

rule FixRef:  # Use bcftools +fixref to set reference vs alternate alleles
    input: "{rawdata}/tmp/{rawdata}_alleles_IDs.bed", REFASTA, REFVCF
    output: "{rawdata}/tmp/{rawdata}-FixRef.bed"
    params:
        prefix = "{rawdata}/tmp/{rawdata}",
        chr_key = config['updates']['chrom_key']
    run:
        if config['updates']['FixRef'] == "true":
            shell(f"{CMD_PREFIX} bash {CODE}/FixRef.sh {{wildcards.rawdata}}_alleles_IDs {{wildcards.rawdata}}/tmp/ {{wildcards.rawdata}}-FixRef {{params.chr_key}} {REFASTA} {REFVCF} t t t t")
        else:
            shell(f"{CMD_PREFIX} plink --bfile {{params.prefix}}_alleles_IDs --make-bed --out {{params.prefix}}-FixRef")


rule QCcombine_query:
    input: "{rawdata}/tmp/{rawdata}-FixRef.bed"
    output: "{rawdata}/{rawdata}-QC.bed"
    params:
        pre1 = "{rawdata}/tmp/{rawdata}",
        pre2 = "{rawdata}/{rawdata}",
        tvm1 = config['QC']['vm1'], tgm = config['QC']['gm'], tvm2 = config['QC']['vm2'],
        hwe = config['QC']['hwe'], maf = config['QC']['maf'], mbs = config['QC']['mbs'],
    run:
        if config['perform_QC'] == 'true':
            with open("scripts/QCcombine_query.sh", 'w') as QCsh:
                cmd = f"{CMD_PREFIX} {PYTHON} {CODE}/QC.py -i {{params.pre1}}-FixRef -d {{wildcards.rawdata}}/tmp/ -o {{wildcards.rawdata}}-QC -p plink -tvm1 {{params.tvm1}} -tgm {{params.tgm}} -tvm2 {{params.tvm2}} -hwe {{params.hwe}} -mbs {{params.mbs}} -maf {{params.maf}}; mv {{params.pre1}}-QC.bed {{wildcards.rawdata}}; mv {{params.pre1}}-QC.bim {{wildcards.rawdata}}; mv {{params.pre1}}-QC.fam {{wildcards.rawdata}}; cp {{wildcards.rawdata}}/tmp/TEMP/DataFixStep3_{{wildcards.rawdata}}_alleles_IDs-RefFixSorted.bim accessory/"
                if config['delete_intermediates'] == 'true': cmd += f"rm -r {{wildcards.rawdata}}/tmp/"
            shell(cmd)
        else:
            shell(f"{CMD_PREFIX} plink --bfile {{params.pre1}}-FixRef --make-bed --out {{params.pre2}}-QC")

#Only execute if FixRef is executed.  Can't delete intermediates from prior step cuz they might be needed.  What about copying bim from TEMP and put it in accessory prior to deleting.
rule restore_strand:
    input: "{rawdata}/{rawdata}-QC.bed"
    output: "{rawdata}/{rawdata}-QC-Ref.bed"
    params:
        bim_file = "accessory/DataFixStep3_{rawdata}_alleles_IDs-RefFixSorted.bim",
        pre1 = "{rawdata}/tmp/{rawdata}",
        pre2 = "{rawdata}/{rawdata}"
    shell: f"{CMD_PREFIX} plink --bfile {{params.pre2}}-QC --make-bed --a2-allele {{params.bim_file}} 6 2 --out {{params.pre2}}-QC-Ref"

rule set_pheno:
    input: "{rawdata}/{rawdata}-QC-Ref.bed"
    output: "{rawdata}/.{rawdata}-PhenoFixed"
    run:
        if f"{{wildcards.rawdata}}" in config['case_datasets'].strip().split(","):
            shell("{CMD_PREFIX} sed -i 's/-9$/2/' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref.fam; touch {output}")
        elif f"{{wildcards.rawdata}}" in config['control_datasets'].strip().split(","):
            shell("{CMD_PREFIX} sed -i 's/-9$/1/' {wildcards.rawdata}/{wildcards.rawdata}-QC-Ref.fam; touch {output}")
        else:
            shell("touch {output}")

rule merge_inputs:
    input: expand("{rawdata}/{rawdata}-QC-Ref.bed", rawdata=QUERY.keys())
    output: f"{OUT}.bed"
    params:
        input_list = ",".join([f"{x}/{x}-QC" for x in QUERY.keys()])
    run:
        if config['merge'] == 'true':
            shell(f"{CMD_PREFIX} {PYTHON} {CODE}/mergeInputs.py -i {{params.input_list}} -d {os.getcwd()} -o {OUT} -p plink")

rule mis_impute_prep:
    input: "{rawdata}/{rawdata}-QC-Ref.bed", "{rawdata}/.{rawdata}-PhenoFixed"
    output: "{rawdata}/{rawdata}.chr{chrom}.vcf.gz"
    params:
        pre = "{rawdata}/{rawdata}",
    run:
        if config['impute_prep'] == 'true':
            shell(f"{CMD_PREFIX} plink --bfile {{params.pre}}-QC-Ref --chr {{wildcards.chrom}} --recode vcf-iid --keep-allele-order --out {{params.pre}}.chr{{wildcards.chrom}};"
                  f" {CMD_PREFIX} bcftools sort -Oz -o {{params.pre}}.chr{{wildcards.chrom}}.vcf.gz {{params.pre}}.chr{{wildcards.chrom}}.vcf; rm {{params.pre}}.chr{{wildcards.chrom}}.vcf")


rule make_report:
    input: expand("{rawdata}/{rawdata}.chr{chrom}.vcf.gz", rawdata=QUERY.keys(), chrom=CHROMS), f"{OUT}-rulegraph.png"
    output: f"{OUT}-report.pdf"
    run:
        with open("scripts/gather_report_data.sh", 'w') as report_cmds:
            report_cmds.write("wc -l */tmp/*txt | grep -v -e scripts -e total | awk \'{split($2,a,\"/\"); split(a[3],b,\".\"); split(b[1],c,\"-\"); print c[1],b[3],$1}\' > accessory/filter.stats\n")
            report_cmds.write("wc -l */tmp/*alleles_IDs.bim | grep -v -e total | awk \'{split($2,a,\"/\"); split(a[3],b,\".\"); split(b[1],c,\"_\"); printf(\"%s raw %s\\n\", c[1],$1)}\' >> accessory/filter.stats\n")
            report_cmds.write("grep -e NS OandE/FixRef.rawdata*err | grep -v Number | cut -d \"=\" -f 2 | awk \'{split($1,a,\".\"); print a[1],$2,$3,$4}\' | sed \'s/ref /ref-/\' | sed \'s/fixed /fixed-/\' | sed \'s/%//\' > accessory/FixRef.stats\n")
            report_cmds.write("zcat " + REFVCF +  " | vawk \'{split(I$CAF,a,\",\"); if($1==20) print $1,$2,$3,a[1]}\' | awk \'{{if(NF==4) print $0}}\' > accessory/ref_freqs.txt\n")
            report_cmds.write("zgrep -v \"#\" */*chr20.vcf.gz | shuf -n 100000 |  vawk \'{print $1,$2,$3, S$*$GT}\' | tr \"/\" \" \" | tr \":\" \" \" > accessory/dat_freqs.txt")
        cmd = f"{CMD_PREFIX} sh scripts/gather_report_data.sh;"
        cmd += """
        echo 'rmarkdown::render("scripts/DataPrep_report.Rmd", \
                  output_file="{output}", \
                  params=list(flt_file="accessory/filter.stats", \
                              FixRef_file="accessory/FixRef.stats", \
                              rulegraph_file="{OUT}-rulegraph.png", \
                              ref_freqs="accessory/ref_freqs.txt", \
                              dat_freq="accessory/dat_freqs.txt", \
                              config_file="workflow/config.yml"))' \
        | R --vanilla
        """
#TODO: Test make_report

